{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff27f54f-8401-4990-b6b4-8728aae84072",
   "metadata": {},
   "source": [
    "## Run Voxtral with llama.cpp\n",
    "[build llama.cpp](https://github.com/ggml-org/llama.cpp/blob/master/docs/build.md)\n",
    "\n",
    "[voxtral](https://mistral.ai/news/voxtral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4aa57c3d-6e39-4f28-b026-729a25aed778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the model\n",
    "# llama-mtmd-cli -hf ggml-org/Voxtral-Mini-3B-2507-GGUF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f09a6a3-ec4b-46d9-b3f2-809156b10a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download https://huggingface.co/mistralai/Voxtral-Mini-3B-2507\n",
    "# cd Voxtral-Mini-3B-2507\n",
    "# python3 ~/llama.cpp/convert_hf_to_gguf.py --outfile model.gguf --outtype f16 .\n",
    "# python3 ~/llama.cpp/convert_hf_to_gguf.py --outfile mmproj-model.gguf --outtype f16 --mmproj ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6db74c1b-8734-4dbf-95cf-1afd798ce9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the server on port 8080 (or any port you prefer)\n",
    "# ./build/bin/llama-server \\\n",
    "#     -m Voxtral-Mini-3B-2507/model.gguf \\\n",
    "#     --mmproj Voxtral-Mini-3B-2507/mmproj-model.gguf \\\n",
    "#     --port 8080 \\\n",
    "#     --host 0.0.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a94d5c4f-6e1a-428e-82bc-468c2d0c197b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def voxtral(audio_file, prompt):\n",
    "    \"\"\"Run Voxtral on audio file with custom prompt\"\"\"\n",
    "    \n",
    "    cmd = [\n",
    "        \"./build/bin/llama-mtmd-cli\",\n",
    "        \"-m\", \"Voxtral-Mini-3B-2507/model.gguf\",\n",
    "        \"--mmproj\", \"Voxtral-Mini-3B-2507/mmproj-model.gguf\",\n",
    "        \"--audio\", audio_file,\n",
    "        \"--top-k\", \"1\",\n",
    "        \"-p\", prompt,\n",
    "    ]\n",
    "    \n",
    "    result = subprocess.run(cmd, capture_output=True)\n",
    "    \n",
    "    # Decode with error handling\n",
    "    try:\n",
    "        output = result.stdout.decode('utf-8', errors='ignore').strip()\n",
    "    except:\n",
    "        # Fallback to latin-1 which accepts all byte values\n",
    "        output = result.stdout.decode('latin-1').strip()\n",
    "    \n",
    "    parts = output.split('\\n\\n', 1) # remove model load log\n",
    "    return  parts[1] if len(parts) > 1 else parts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ba9d5868-36a3-4bbb-af62-e9bcffb6ef05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transcribe use cases\n",
    "transcript = voxtral(\n",
    "    \"first_30_seconds.wav\",\n",
    "    \"Transcribe\"\n",
    ")\n",
    "\n",
    "# print(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6507241e-9dae-40a3-a629-e87afefb4738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q&A use cases\n",
    "answer = voxtral(\n",
    "    \"first_30_seconds.wav\",\n",
    "    \"Is TAG mention in this meeting? If TAG is mention in what context?\"\n",
    ")\n",
    "\n",
    "# print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "23653d5e-9c41-4088-9211-7683339fa6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 mins meeting \n",
    "belfrage = voxtral(\n",
    "    \"first_10_mins.wav\",\n",
    "    \"Is Belfrage or Belfrage Team mentioned in this meeting? If yes, in what context? Is it in negative light?\"\n",
    ")\n",
    "\n",
    "# print(belfrage)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
