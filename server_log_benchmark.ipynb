{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ccb650d-1394-47e2-bde5-bff17ee6d904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: litellm in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (1.38.2)\n",
      "Requirement already satisfied: aiohttp in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from litellm) (3.9.3)\n",
      "Requirement already satisfied: click in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from litellm) (8.1.7)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from litellm) (6.11.0)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from litellm) (3.1.3)\n",
      "Requirement already satisfied: openai>=1.27.0 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from litellm) (1.35.10)\n",
      "Requirement already satisfied: python-dotenv>=0.2.0 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from litellm) (1.0.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from litellm) (2.31.0)\n",
      "Requirement already satisfied: tiktoken>=0.4.0 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from litellm) (0.7.0)\n",
      "Requirement already satisfied: tokenizers in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from litellm) (0.15.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from importlib-metadata>=6.8.0->litellm) (3.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from jinja2<4.0.0,>=3.1.2->litellm) (2.1.4)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from openai>=1.27.0->litellm) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from openai>=1.27.0->litellm) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from openai>=1.27.0->litellm) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from openai>=1.27.0->litellm) (2.4.2)\n",
      "Requirement already satisfied: sniffio in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from openai>=1.27.0->litellm) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from openai>=1.27.0->litellm) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from openai>=1.27.0->litellm) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from requests<3.0.0,>=2.31.0->litellm) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from requests<3.0.0,>=2.31.0->litellm) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from requests<3.0.0,>=2.31.0->litellm) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from requests<3.0.0,>=2.31.0->litellm) (2023.11.17)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from tiktoken>=0.4.0->litellm) (2023.12.25)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from aiohttp->litellm) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from aiohttp->litellm) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from aiohttp->litellm) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from aiohttp->litellm) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from aiohttp->litellm) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from aiohttp->litellm) (4.0.3)\n",
      "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from tokenizers->litellm) (0.20.3)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai>=1.27.0->litellm) (1.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai>=1.27.0->litellm) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.27.0->litellm) (0.14.0)\n",
      "Requirement already satisfied: filelock in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers->litellm) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers->litellm) (2023.12.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers->litellm) (6.0.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers->litellm) (23.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->openai>=1.27.0->litellm) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->openai>=1.27.0->litellm) (2.10.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: mermaid-magic in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (0.1.4)\n",
      "Requirement already satisfied: ipython in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from mermaid-magic) (8.18.1)\n",
      "Requirement already satisfied: decorator in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from ipython->mermaid-magic) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from ipython->mermaid-magic) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from ipython->mermaid-magic) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from ipython->mermaid-magic) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from ipython->mermaid-magic) (2.17.2)\n",
      "Requirement already satisfied: stack-data in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from ipython->mermaid-magic) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from ipython->mermaid-magic) (5.14.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from ipython->mermaid-magic) (4.9.0)\n",
      "Requirement already satisfied: exceptiongroup in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from ipython->mermaid-magic) (1.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from ipython->mermaid-magic) (4.9.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from jedi>=0.16->ipython->mermaid-magic) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from pexpect>4.3->ipython->mermaid-magic) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython->mermaid-magic) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from stack-data->ipython->mermaid-magic) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from stack-data->ipython->mermaid-magic) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from stack-data->ipython->mermaid-magic) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from asttokens>=2.1.0->stack-data->ipython->mermaid-magic) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install litellm\n",
    "!pip install mermaid-magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8783f6ba-b317-4d27-9a81-899422ca6f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mermaid_magic extension is already loaded. To reload it, use:\n",
      "  %reload_ext mermaid_magic\n"
     ]
    }
   ],
   "source": [
    "%load_ext mermaid_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "72969a90-1e53-4aa3-aab5-d3ddf36800e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"mermaid\">\n",
       "    graph TD\n",
       "    A[Start Jupyter Notebook] --> B{Load Configuration};\n",
       "    B --> C{Load Benchmark Data};\n",
       "    C --> D{Select LLM Model via Ollama Endpoint};\n",
       "    D --> E{Iterate Through Log Snippets Scenarios};\n",
       "    E --> F{For Each Log Snippet};\n",
       "    F --> G{Format Prompt for LLM};\n",
       "    G --> H{Send Request to Ollama Endpoint};\n",
       "    H --> I{Receive LLM Response};\n",
       "    I --> J{Evaluate LLM Response};\n",
       "    J --> K{Store Evaluation Metrics};\n",
       "    K --> E;\n",
       "    E -- All Snippets Processed --> L{Aggregate and Analyze Results};\n",
       "    L --> M{Visualize Results};\n",
       "    M --> N[End Report Findings];\n",
       "\n",
       "    subgraph \"Model Abstraction Layer Pluggable\"\n",
       "        O[Ollama Model 1 Interface]\n",
       "        P[Ollama Model 2 Interface]\n",
       "        Q[More Models...]\n",
       "    end\n",
       "\n",
       "    D -.-> O;\n",
       "    D -.-> P;\n",
       "    D -.-> Q;\n",
       "\n",
       "    subgraph \"Benchmark Data Store\"\n",
       "        R[Log Snippet 1 example Error Log]\n",
       "        S[Expected Analysis 1 Ground Truth]\n",
       "        T[Log Snippet 2 example Security Event]\n",
       "        U[Expected Analysis 2 Ground Truth]\n",
       "        V[More Snippets...]\n",
       "    end\n",
       "\n",
       "    C --> R;\n",
       "    C --> S;\n",
       "    C --> T;\n",
       "    C --> U;\n",
       "    C --> V;\n",
       "\n",
       "    subgraph \"Evaluation Logic\"\n",
       "        W[Define Evaluation Criteria example Accuracy Relevance Completeness]\n",
       "        X[Scoring Mechanism example Keyword Match Semantic Similarity LLM as a judge]\n",
       "    end\n",
       "\n",
       "    J --> W;\n",
       "    J --> X;\n",
       "\n",
       "    </div>\n",
       "\n",
       "    <script>\n",
       "      if (typeof mermaid === 'undefined') {\n",
       "        var script = document.createElement('script');\n",
       "        script.src = \"https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js\";\n",
       "        script.onload = () => mermaid.initialize({ startOnLoad: true });\n",
       "        document.head.appendChild(script);\n",
       "      } else {\n",
       "        mermaid.init();\n",
       "      }\n",
       "    </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%mermaid\n",
    "graph TD\n",
    "    A[Start Jupyter Notebook] --> B{Load Configuration};\n",
    "    B --> C{Load Benchmark Data};\n",
    "    C --> D{Select LLM Model via Ollama Endpoint};\n",
    "    D --> E{Iterate Through Log Snippets Scenarios};\n",
    "    E --> F{For Each Log Snippet};\n",
    "    F --> G{Format Prompt for LLM};\n",
    "    G --> H{Send Request to Ollama Endpoint};\n",
    "    H --> I{Receive LLM Response};\n",
    "    I --> J{Evaluate LLM Response};\n",
    "    J --> K{Store Evaluation Metrics};\n",
    "    K --> E;\n",
    "    E -- All Snippets Processed --> L{Aggregate and Analyze Results};\n",
    "    L --> M{Visualize Results};\n",
    "    M --> N[End Report Findings];\n",
    "\n",
    "    subgraph \"Model Abstraction Layer Pluggable\"\n",
    "        O[Ollama Model 1 Interface]\n",
    "        P[Ollama Model 2 Interface]\n",
    "        Q[More Models...]\n",
    "    end\n",
    "\n",
    "    D -.-> O;\n",
    "    D -.-> P;\n",
    "    D -.-> Q;\n",
    "\n",
    "    subgraph \"Benchmark Data Store\"\n",
    "        R[Log Snippet 1 example Error Log]\n",
    "        S[Expected Analysis 1 Ground Truth]\n",
    "        T[Log Snippet 2 example Security Event]\n",
    "        U[Expected Analysis 2 Ground Truth]\n",
    "        V[More Snippets...]\n",
    "    end\n",
    "\n",
    "    C --> R;\n",
    "    C --> S;\n",
    "    C --> T;\n",
    "    C --> U;\n",
    "    C --> V;\n",
    "\n",
    "    subgraph \"Evaluation Logic\"\n",
    "        W[Define Evaluation Criteria example Accuracy Relevance Completeness]\n",
    "        X[Scoring Mechanism example Keyword Match Semantic Similarity LLM as a judge]\n",
    "    end\n",
    "\n",
    "    J --> W;\n",
    "    J --> X;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e41012fb-4806-41cb-8bb2-c01b364f7eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "class LogProcessor:\n",
    "    \"\"\"\n",
    "    A class to load, process, and chunk log data for LLM analysis.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        \"\"\"\n",
    "        Initializes the LogProcessor.\n",
    "\n",
    "        Args:\n",
    "            config (dict): Configuration dictionary. Expected keys:\n",
    "                - \"window_size_lines\" (int): Number of log lines per chunk.\n",
    "                - \"max_line_length\" (int): Maximum characters allowed per line.\n",
    "                                           Lines exceeding this will be truncated.\n",
    "                - \"slide_step\" (int): Number of lines the window slides forward\n",
    "                                      for the next chunk.\n",
    "        \"\"\"\n",
    "        if not isinstance(config, dict):\n",
    "            raise TypeError(\"Config must be a dictionary.\")\n",
    "\n",
    "        self.config = config\n",
    "        self._validate_config()\n",
    "\n",
    "        self.raw_log_lines = []\n",
    "        self.processed_log_lines = []\n",
    "\n",
    "    def _validate_config(self):\n",
    "        \"\"\"Validates the provided configuration.\"\"\"\n",
    "        required_keys = [\"window_size_lines\", \"max_line_length\", \"slide_step\"]\n",
    "        for key in required_keys:\n",
    "            if key not in self.config:\n",
    "                raise ValueError(f\"Missing required config key: {key}\")\n",
    "\n",
    "        if not isinstance(self.config[\"window_size_lines\"], int) or self.config[\"window_size_lines\"] <= 0:\n",
    "            raise ValueError(\"Config 'window_size_lines' must be a positive integer.\")\n",
    "        if not isinstance(self.config[\"max_line_length\"], int) or self.config[\"max_line_length\"] <= 0:\n",
    "            raise ValueError(\"Config 'max_line_length' must be a positive integer.\")\n",
    "        if not isinstance(self.config[\"slide_step\"], int) or self.config[\"slide_step\"] <= 0:\n",
    "            raise ValueError(\"Config 'slide_step' must be a positive integer.\")\n",
    "\n",
    "    def _truncate_line(self, line: str) -> str:\n",
    "        \"\"\"\n",
    "        Truncates a single line to the configured max_line_length.\n",
    "        \"\"\"\n",
    "        max_len = self.config[\"max_line_length\"]\n",
    "        if len(line) > max_len:\n",
    "            return line[:max_len]\n",
    "        return line\n",
    "\n",
    "    def load_logs(self, log_source):\n",
    "        \"\"\"\n",
    "        Loads log lines from a specified source (file path or list of strings).\n",
    "        Each loaded line is immediately processed (truncated).\n",
    "\n",
    "        Args:\n",
    "            log_source (str or list): The source of the log data.\n",
    "                                      If str, it's treated as a file path.\n",
    "                                      If list, it's treated as a list of log line strings.\n",
    "\n",
    "        Raises:\n",
    "            FileNotFoundError: If log_source is a path and the file doesn't exist.\n",
    "            IOError: If there's an error reading the file.\n",
    "            TypeError: If log_source is not a str or list, or if list elements are not strings.\n",
    "        \"\"\"\n",
    "        self.raw_log_lines = []\n",
    "        self.processed_log_lines = [] # Clear previously processed lines\n",
    "\n",
    "        current_raw_lines = []\n",
    "        if isinstance(log_source, str):\n",
    "            if not os.path.exists(log_source):\n",
    "                raise FileNotFoundError(f\"Log file not found: {log_source}\")\n",
    "            try:\n",
    "                with open(log_source, 'r', encoding='utf-8') as f:\n",
    "                    # Use rstrip to remove various trailing newline characters\n",
    "                    current_raw_lines = [line.rstrip('\\r\\n') for line in f]\n",
    "            except Exception as e:\n",
    "                raise IOError(f\"Error reading log file {log_source}: {e}\")\n",
    "        elif isinstance(log_source, list):\n",
    "            if not all(isinstance(line, str) for line in log_source):\n",
    "                raise TypeError(\"If log_source is a list, all its elements must be strings.\")\n",
    "            # Also strip various trailing newlines from list input for consistency\n",
    "            current_raw_lines = [line.rstrip('\\r\\n') for line in log_source]\n",
    "        else:\n",
    "            raise TypeError(\"log_source must be a file path (str) or a list of strings.\")\n",
    "\n",
    "        self.raw_log_lines = current_raw_lines\n",
    "        # Process (truncate) lines immediately after loading\n",
    "        self.processed_log_lines = [self._truncate_line(line) for line in self.raw_log_lines]\n",
    "\n",
    "\n",
    "    def get_chunks(self):\n",
    "        \"\"\"\n",
    "        Generates log chunks based on the configured window size and slide step.\n",
    "        Each chunk is a list of processed (truncated) log lines.\n",
    "        This method is a generator.\n",
    "\n",
    "        Yields:\n",
    "            list: A chunk of log lines (list of strings).\n",
    "                  Returns an empty iterator if no logs are loaded or logs are empty.\n",
    "        \"\"\"\n",
    "        if not self.processed_log_lines:\n",
    "            return iter([]) # Return an empty iterator if no processed lines\n",
    "\n",
    "        window_size = self.config[\"window_size_lines\"]\n",
    "        step = self.config[\"slide_step\"]\n",
    "        num_processed_lines = len(self.processed_log_lines)\n",
    "\n",
    "        current_pos = 0\n",
    "        while current_pos < num_processed_lines:\n",
    "            window_end = current_pos + window_size\n",
    "            chunk = self.processed_log_lines[current_pos:window_end]\n",
    "            \n",
    "            if chunk: # Only yield if the chunk is not empty\n",
    "                yield chunk\n",
    "            \n",
    "            # Optimization: if the last chunk was smaller than window_size,\n",
    "            # and step is 1, we might generate empty or redundant small chunks.\n",
    "            # However, the current logic is simpler and correct.\n",
    "            # The main check `current_pos < num_processed_lines` handles termination.\n",
    "            # If the last chunk was full or partial, and current_pos + step >= num_processed_lines,\n",
    "            # the next iteration won't yield if the slice is empty or current_pos is too high.\n",
    "\n",
    "            # If the last chunk was already smaller than the window size,\n",
    "            # and we've taken all lines, further steps won't yield new full windows.\n",
    "            # The condition `if chunk:` already handles not yielding empty lists if\n",
    "            # current_pos somehow goes beyond where meaningful slices can be made.\n",
    "            if window_end >= num_processed_lines and len(chunk) < window_size:\n",
    "                 # If the current chunk is the last possible partial chunk\n",
    "                 if current_pos + step >= num_processed_lines and len(chunk) < step : # and we won't get a new line by sliding\n",
    "                    pass # allow loop to terminate naturally by current_pos update\n",
    "\n",
    "            current_pos += step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "da1798c3-9d4c-4a65-bc73-e2946687db0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_get_chunks_basic_sliding_window (__main__.TestLogProcessor) ... ok\n",
      "test_get_chunks_empty_logs (__main__.TestLogProcessor) ... ok\n",
      "test_get_chunks_non_overlapping (__main__.TestLogProcessor) ... ok\n",
      "test_get_chunks_step_larger_than_window (__main__.TestLogProcessor) ... ok\n",
      "test_get_chunks_total_lines_equals_window (__main__.TestLogProcessor) ... ok\n",
      "test_get_chunks_total_lines_less_than_window (__main__.TestLogProcessor) ... ok\n",
      "test_get_chunks_with_line_truncation (__main__.TestLogProcessor) ... ok\n",
      "test_init_invalid_config_value_non_positive (__main__.TestLogProcessor) ... ok\n",
      "test_init_invalid_config_value_type (__main__.TestLogProcessor) ... ok\n",
      "test_init_missing_config_key (__main__.TestLogProcessor) ... ok\n",
      "test_init_non_dict_config (__main__.TestLogProcessor) ... ok\n",
      "test_load_empty_file (__main__.TestLogProcessor) ... ok\n",
      "test_load_empty_list (__main__.TestLogProcessor) ... ok\n",
      "test_load_from_file_and_truncate (__main__.TestLogProcessor) ... ok\n",
      "test_load_from_list_and_truncate (__main__.TestLogProcessor) ... ok\n",
      "test_load_invalid_source_type (__main__.TestLogProcessor) ... ok\n",
      "test_load_list_with_non_string_elements (__main__.TestLogProcessor) ... ok\n",
      "test_load_non_existent_file (__main__.TestLogProcessor) ... ok\n",
      "test_load_strips_trailing_newlines_from_list_input (__main__.TestLogProcessor) ... ok\n",
      "test_reloading_logs_clears_previous_and_chunks_new (__main__.TestLogProcessor) ... ok\n",
      "test_valid_initialization (__main__.TestLogProcessor) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 21 tests in 0.021s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "# Assuming the LogProcessor class definition is above or imported\n",
    "\n",
    "class TestLogProcessor(unittest.TestCase):\n",
    "\n",
    "    def setUp(self):\n",
    "        self.temp_file = tempfile.NamedTemporaryFile(mode=\"w+\", delete=False, encoding=\"utf-8\")\n",
    "        self.temp_file_path = self.temp_file.name\n",
    "\n",
    "    def tearDown(self):\n",
    "        self.temp_file.close()\n",
    "        os.remove(self.temp_file_path)\n",
    "\n",
    "    def _write_to_temp_file(self, lines):\n",
    "        self.temp_file.seek(0)\n",
    "        self.temp_file.truncate()\n",
    "        for line in lines:\n",
    "            self.temp_file.write(line + \"\\n\")\n",
    "        self.temp_file.flush()\n",
    "\n",
    "    # 1. Initialization Tests\n",
    "    def test_valid_initialization(self):\n",
    "        config = {\"window_size_lines\": 3, \"max_line_length\": 10, \"slide_step\": 1}\n",
    "        processor = LogProcessor(config)\n",
    "        self.assertEqual(processor.config, config)\n",
    "\n",
    "    def test_init_missing_config_key(self):\n",
    "        with self.assertRaisesRegex(ValueError, \"Missing required config key: max_line_length\"):\n",
    "            LogProcessor({\"window_size_lines\": 3, \"slide_step\": 1})\n",
    "\n",
    "    def test_init_invalid_config_value_type(self):\n",
    "        with self.assertRaisesRegex(ValueError, \"must be a positive integer\"):\n",
    "            LogProcessor({\"window_size_lines\": \"3\", \"max_line_length\": 10, \"slide_step\": 1})\n",
    "\n",
    "    def test_init_invalid_config_value_non_positive(self):\n",
    "        with self.assertRaisesRegex(ValueError, \"must be a positive integer\"):\n",
    "            LogProcessor({\"window_size_lines\": 0, \"max_line_length\": 10, \"slide_step\": 1})\n",
    "\n",
    "    def test_init_non_dict_config(self):\n",
    "        with self.assertRaisesRegex(TypeError, \"Config must be a dictionary.\"):\n",
    "            LogProcessor(\"not_a_dict\")\n",
    "\n",
    "    # 2. Log Loading and Line Processing Tests\n",
    "    def test_load_from_list_and_truncate(self):\n",
    "        config = {\"window_size_lines\": 1, \"max_line_length\": 5, \"slide_step\": 1}\n",
    "        processor = LogProcessor(config)\n",
    "        logs = [\"AAAAA\", \"BBBBBBBBB\", \"CCC\\n\", \"DD\"]\n",
    "        processor.load_logs(logs)\n",
    "        expected_processed = [\"AAAAA\", \"BBBBB\", \"CCC\", \"DD\"]\n",
    "        self.assertEqual(processor.processed_log_lines, expected_processed)\n",
    "\n",
    "    def test_load_from_file_and_truncate(self):\n",
    "        config = {\"window_size_lines\": 1, \"max_line_length\": 3, \"slide_step\": 1}\n",
    "        processor = LogProcessor(config)\n",
    "        file_lines = [\"apple\", \"banana\", \"pi\"]\n",
    "        self._write_to_temp_file(file_lines)\n",
    "        processor.load_logs(self.temp_file_path)\n",
    "        expected_processed = [\"app\", \"ban\", \"pi\"]\n",
    "        self.assertEqual(processor.processed_log_lines, expected_processed)\n",
    "\n",
    "    def test_load_empty_list(self):\n",
    "        config = {\"window_size_lines\": 1, \"max_line_length\": 10, \"slide_step\": 1}\n",
    "        processor = LogProcessor(config)\n",
    "        processor.load_logs([])\n",
    "        self.assertEqual(processor.processed_log_lines, [])\n",
    "\n",
    "    def test_load_empty_file(self):\n",
    "        config = {\"window_size_lines\": 1, \"max_line_length\": 10, \"slide_step\": 1}\n",
    "        processor = LogProcessor(config)\n",
    "        self._write_to_temp_file([])\n",
    "        processor.load_logs(self.temp_file_path)\n",
    "        self.assertEqual(processor.processed_log_lines, [])\n",
    "\n",
    "    def test_load_non_existent_file(self):\n",
    "        config = {\"window_size_lines\": 1, \"max_line_length\": 10, \"slide_step\": 1}\n",
    "        processor = LogProcessor(config)\n",
    "        with self.assertRaises(FileNotFoundError):\n",
    "            processor.load_logs(\"non_existent_file.log\")\n",
    "\n",
    "    def test_load_invalid_source_type(self):\n",
    "        config = {\"window_size_lines\": 1, \"max_line_length\": 10, \"slide_step\": 1}\n",
    "        processor = LogProcessor(config)\n",
    "        with self.assertRaisesRegex(TypeError, \"log_source must be a file path .* or a list\"):\n",
    "            processor.load_logs(123)\n",
    "\n",
    "    def test_load_list_with_non_string_elements(self):\n",
    "        config = {\"window_size_lines\": 1, \"max_line_length\": 10, \"slide_step\": 1}\n",
    "        processor = LogProcessor(config)\n",
    "        with self.assertRaisesRegex(TypeError, \"all its elements must be strings\"):\n",
    "            processor.load_logs([\"line1\", 123, \"line3\"])\n",
    "            \n",
    "    def test_load_strips_trailing_newlines_from_list_input(self): # This test should now pass\n",
    "        config = {\"window_size_lines\": 1, \"max_line_length\": 10, \"slide_step\": 1}\n",
    "        processor = LogProcessor(config)\n",
    "        logs = [\"line1\\n\", \"line2\\r\\n\", \"line3\\r\", \"line4\"]\n",
    "        processor.load_logs(logs)\n",
    "        expected_processed = [\"line1\", \"line2\", \"line3\", \"line4\"]\n",
    "        self.assertEqual(processor.processed_log_lines, expected_processed)\n",
    "\n",
    "    # 3. Chunk Generation Tests\n",
    "    def test_get_chunks_basic_sliding_window(self):\n",
    "        config = {\"window_size_lines\": 2, \"max_line_length\": 10, \"slide_step\": 1}\n",
    "        processor = LogProcessor(config)\n",
    "        logs = [\"L1\", \"L2\", \"L3\", \"L4\"]\n",
    "        processor.load_logs(logs)\n",
    "        chunks = list(processor.get_chunks())\n",
    "        expected_chunks = [\n",
    "            [\"L1\", \"L2\"],\n",
    "            [\"L2\", \"L3\"],\n",
    "            [\"L3\", \"L4\"],\n",
    "            [\"L4\"]\n",
    "        ]\n",
    "        self.assertEqual(chunks, expected_chunks)\n",
    "\n",
    "    def test_get_chunks_non_overlapping(self):\n",
    "        config = {\"window_size_lines\": 2, \"max_line_length\": 10, \"slide_step\": 2}\n",
    "        processor = LogProcessor(config)\n",
    "        logs = [\"L1\", \"L2\", \"L3\", \"L4\", \"L5\"]\n",
    "        processor.load_logs(logs)\n",
    "        chunks = list(processor.get_chunks())\n",
    "        expected_chunks = [\n",
    "            [\"L1\", \"L2\"],\n",
    "            [\"L3\", \"L4\"],\n",
    "            [\"L5\"]\n",
    "        ]\n",
    "        self.assertEqual(chunks, expected_chunks)\n",
    "\n",
    "    def test_get_chunks_step_larger_than_window(self):\n",
    "        config = {\"window_size_lines\": 2, \"max_line_length\": 10, \"slide_step\": 3}\n",
    "        processor = LogProcessor(config)\n",
    "        logs = [\"L1\", \"L2\", \"L3\", \"L4\", \"L5\", \"L6\"]\n",
    "        processor.load_logs(logs)\n",
    "        chunks = list(processor.get_chunks())\n",
    "        expected_chunks = [\n",
    "            [\"L1\", \"L2\"], \n",
    "            [\"L4\", \"L5\"] \n",
    "        ]\n",
    "        self.assertEqual(chunks, expected_chunks)\n",
    "\n",
    "    def test_get_chunks_total_lines_less_than_window(self): # Corrected expectation\n",
    "        config = {\"window_size_lines\": 5, \"max_line_length\": 10, \"slide_step\": 1}\n",
    "        processor = LogProcessor(config)\n",
    "        logs = [\"L1\", \"L2\", \"L3\"]\n",
    "        processor.load_logs(logs)\n",
    "        chunks = list(processor.get_chunks())\n",
    "        # If slide_step is 1, it will slide until only the last element is left\n",
    "        expected_chunks = [\n",
    "            [\"L1\", \"L2\", \"L3\"],\n",
    "            [\"L2\", \"L3\"],\n",
    "            [\"L3\"]\n",
    "        ]\n",
    "        self.assertEqual(chunks, expected_chunks)\n",
    "\n",
    "    def test_get_chunks_total_lines_equals_window(self):\n",
    "        config = {\"window_size_lines\": 3, \"max_line_length\": 10, \"slide_step\": 1}\n",
    "        processor = LogProcessor(config)\n",
    "        logs = [\"L1\", \"L2\", \"L3\"]\n",
    "        processor.load_logs(logs)\n",
    "        chunks = list(processor.get_chunks())\n",
    "        expected_chunks_slide1 = [[\"L1\", \"L2\", \"L3\"], [\"L2\", \"L3\"], [\"L3\"]]\n",
    "        self.assertEqual(chunks, expected_chunks_slide1)\n",
    "\n",
    "    def test_get_chunks_empty_logs(self):\n",
    "        config = {\"window_size_lines\": 3, \"max_line_length\": 10, \"slide_step\": 1}\n",
    "        processor = LogProcessor(config)\n",
    "        processor.load_logs([]) \n",
    "        chunks = list(processor.get_chunks())\n",
    "        self.assertEqual(chunks, [])\n",
    "\n",
    "    def test_get_chunks_with_line_truncation(self):\n",
    "        config = {\"window_size_lines\": 1, \"max_line_length\": 3, \"slide_step\": 1}\n",
    "        processor = LogProcessor(config)\n",
    "        logs = [\"AAAAA\", \"BB\", \"CCCCC\"]\n",
    "        processor.load_logs(logs)\n",
    "        chunks = list(processor.get_chunks())\n",
    "        expected_chunks = [\n",
    "            [\"AAA\"],\n",
    "            [\"BB\"],\n",
    "            [\"CCC\"]\n",
    "        ]\n",
    "        self.assertEqual(chunks, expected_chunks)\n",
    "\n",
    "    def test_reloading_logs_clears_previous_and_chunks_new(self):\n",
    "        config = {\"window_size_lines\": 1, \"max_line_length\": 10, \"slide_step\": 1}\n",
    "        processor = LogProcessor(config)\n",
    "        \n",
    "        logs1 = [\"A\", \"B\"]\n",
    "        processor.load_logs(logs1)\n",
    "        chunks1 = list(processor.get_chunks())\n",
    "        self.assertEqual(chunks1, [[\"A\"], [\"B\"]])\n",
    "        self.assertEqual(processor.processed_log_lines, [\"A\", \"B\"])\n",
    "\n",
    "        logs2 = [\"X\", \"Y\", \"Z\"]\n",
    "        processor.load_logs(logs2) \n",
    "        chunks2 = list(processor.get_chunks())\n",
    "        self.assertEqual(chunks2, [[\"X\"], [\"Y\"], [\"Z\"]])\n",
    "        self.assertEqual(processor.processed_log_lines, [\"X\", \"Y\", \"Z\"])\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # If running in a script:\n",
    "    # unittest.main() \n",
    "    # If running in Jupyter or similar:\n",
    "    suite = unittest.TestSuite()\n",
    "    suite.addTest(unittest.makeSuite(TestLogProcessor))\n",
    "    runner = unittest.TextTestRunner(verbosity=2) # Increased verbosity\n",
    "    runner.run(suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a47c38-3f31-4b9a-9bdf-c16740f91853",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
